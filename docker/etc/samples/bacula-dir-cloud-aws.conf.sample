# bacula-dir-cloud.conf
#
# JobDefs
# Job
# Restore
# Pool
# Autochanger
#


# Template to store in cloud
JobDefs {
  Name = "DefaultJobToCloudAWS"
  Type = Backup
  Level = Incremental
  Client = bacula-fd
  FileSet = "Full Set"
  Schedule = "WeeklyCycle"
  Storage = "CloudS3AWS"
  Messages = Standard
  Pool = CloudAWS
  SpoolAttributes = yes
  Priority = 10
  Write Bootstrap = "/opt/bacula/working/%c.bsr"
}

# Jobs
Job {
  Name = "BackupClient1ToCloudAWS"
  JobDefs = "DefaultJobToCloudAWS"
}



# Restore
Job {
  Name = "RestoreFromCloudAWS"
  Type = Restore
  Client=bacula-fd
  Storage = CloudS3AWS
  FileSet="Full Set"
  Pool = CloudAWS
  Messages = Standard
  Where = /tmp/bacula-restores
}



# Cloud Pool definition
Pool {
  Name = CloudAWS
  Pool Type = Backup
  Recycle = no                        # Bacula can automatically recycle Volumes
  AutoPrune = yes                     # Prune expired volumes
  Volume Retention = 365 days         # one year
  Maximum Volume Jobs = 1             #
  # Maximum Volume Bytes = 100M          # Limit Volume size to something reasonable
  Label Format = "Vol-JobId-${JobId}"      # Auto label
}


# Autochanger definition
Autochanger {
  Name = "CloudS3AWS"
# Do not use "localhost" here
  Address = bacula-sd                # N.B. Use a fully qualified name here
  SDPort = 9103
  Password = "TS8EQJ99iLFSK39oJy33YqkZ98v4ZapjRcA+j1N6ED1n"
  Device = "CloudAutoChangerS3"
  Media Type = "CloudType"
  Maximum Concurrent Jobs = 10        # run up to 10 jobs a the same time
}
